import os
# Number of reads for a chunk

# Config structure:
# chunk_size: 1000000
# genome:
#   bowtie2: path/to/bowtie/index
#   star: path/to/star/index
# samples:
#   sample_name:
#       R1: path/to/R1.fastq.gz
#       R2: path/to/R2.fastq.gz
#       ATAC_I2: ["ATGCATA", "GCATACAA"]
#       RNA_I2:  ["ATGCATA", "CCGGATAA"]
#       reads: [autogenerated]

# sequencing:
#   run1:
#     type: fastq
#     R1: path/to/R1.fastq.gz
#     R2: path/to/R2.fastq.gz
#   run2:
#     type: bcl
#     ATAC_I2: 
#       - ATGCATAG
#       - GCATACAA
#     RNA_I2:
#       - CGGACTGC
#       - AGCCGTTC
#
workdir: config["output_dir"]

chunk_size = config["chunk_size"]

for sample in config["samples"]:
    counts_path = f"{sample}/fastq/read_count.txt"
    if not os.path.exists(counts_path):
        raise RuntimeError(f"Sample {sample} not yet processed by prep_fastq.smk")
    config["samples"][sample]["reads"] = int(open(counts_path).read().strip())
del sample

rule all:
    input:
        expand("{sample}/fastq/match_barcodes/{assay}/{chunk}_R1.fastq.zst", 
            sample=config["samples"].keys(),
            assay=["ATAC", "RNA"],
            chunk=[1]),
        expand("{sample}/fastq/trim_adapters/{assay}/{chunk}_interleaved.fastq.zst",
            sample=config["samples"].keys(),
            assay=["ATAC", "RNA"],
            chunk=[1]),
        expand('{sample}/atac/bowtie2/{chunk}.bam', sample=config["samples"].keys(), chunk=[1]),
        expand('{sample}/atac/fragments.tsv.gz', sample=config["samples"].keys())

#############################
### ATAC + RNA fastq processing 
#############################

# Split fastqs
rule split_fastqs:
    input:
        fastq = lambda w: config["samples"][w.sample][w.read],
        read_count = "{sample}/fastq/read_count.txt"
    output:
        chunks = temp(directory("{sample}/fastq/split_fastqs/{read}"))
    params:
        script = srcdir("scripts/split_fastq.py")
    log: '{sample}/logs/split_fastqs_{read}.log'
    shell: "python3 {params.script} {input.fastq} {output.chunks} --reads {chunk_size} 2> {log}"

# Perform barcode matching
rule match_barcodes:
    input: 
        R1 = expand(rules.split_fastqs.output.chunks, read="R1", allow_missing=True),
        R2 = expand(rules.split_fastqs.output.chunks, read="R2", allow_missing=True)
    output:
        R1_RNA = temp("{sample}/fastq/match_barcodes/RNA/{chunk}_R1.fastq.zst"),
        R2_RNA = temp("{sample}/fastq/match_barcodes/RNA/{chunk}_R2.fastq.zst"),
        R1_ATAC = temp("{sample}/fastq/match_barcodes/ATAC/{chunk}_R1.fastq.zst"),
        R2_ATAC = temp("{sample}/fastq/match_barcodes/ATAC/{chunk}_R2.fastq.zst"),
        stats = "{sample}/qc_stats/chunks/match_barcodes/{chunk}.json",
    params:
        script = srcdir("scripts/match_barcodes.py"),
        ATAC_I2 = lambda w: " ".join(config["samples"][w.sample]["ATAC_I2"]),
        RNA_I2 = lambda w: " ".join(config["samples"][w.sample]["RNA_I2"]),
        BC1 = srcdir("config/barcodes/Round1.tsv"),
        BC2 = srcdir("config/barcodes/Round2.tsv"),
        BC3 = srcdir("config/barcodes/Round3.tsv"),
        R1_in = "{sample}/fastq/split_fastqs/R1/{chunk}.fastq.zst",
        R2_in = "{sample}/fastq/split_fastqs/R2/{chunk}.fastq.zst",
    log: '{sample}/logs/match_barcodes/{chunk}.log'
    # Here we use process substitution like >() and <() to use zstandard to 
    # compress + decompress our inputs/outputs
    shell: "python3 {params.script} "
        " --R1_in <(zstd -dc {params.R1_in}) --R2_in <(zstd -dc {params.R2_in}) "
        " --R1_RNA >(zstd --fast=1 -q -o {output.R1_RNA}) "
        " --R2_RNA >(zstd --fast=1 -q -o {output.R2_RNA}) "
        " --R1_ATAC >(zstd --fast=1 -q -o {output.R1_ATAC}) "
        " --R2_ATAC >(zstd --fast=1 -q -o {output.R2_ATAC}) "
        " --ATAC_I2 {params.ATAC_I2} --RNA_I2 {params.RNA_I2} "
        " --BC1 {params.BC1} --BC2 {params.BC2} --BC3 {params.BC3} "
        " --json_stats {output.stats} "
        " 2> {log} "

# Remove adapter ends from the raw fastq reads
rule trim_adapters:
    input: 
        R1 = "{sample}/fastq/match_barcodes/{assay}/{chunk}_R1.fastq.zst",
        R2 = "{sample}/fastq/match_barcodes/{assay}/{chunk}_R2.fastq.zst",
    output:
        interleaved = temp("{sample}/fastq/trim_adapters/{assay}/{chunk}_interleaved.fastq.zst"),
        report_json = "{sample}/qc_stats/chunks/trim_adapters/{assay}/{chunk}.json"
    threads: 4
    log: '{sample}/logs/trim_adapters/{assay}/{chunk}.log'
    shell: "fastp --in1 <(zstd -dc {input.R1}) --in2 <(zstd -dc {input.R2}) "
        " --adapter_sequence    CTGTCTCTTATACACATCTCCGAGCCCACGAGAC "
        " --adapter_sequence_r2 CTGTCTCTTATACACATCTGACGCTGCCGACGA "
        " -j {output.report_json} -G -Q -L -w {threads} 2> {log} "
        " --stdout | zstd --fast=1 -q -o {output.interleaved}"

#############################
### ATAC-specific workflow 
#############################

# Align ATAC reads with bowtie2, and filter to good quality reads only
rule atac_bowtie2:
    input: 
        fastq = expand(rules.trim_adapters.output.interleaved, assay="ATAC", allow_missing=True)
    output: temp('{sample}/atac/bowtie2/{chunk}.bam')
    threads: 16
    params:
        index = config["genome"]["bowtie2"]
    log: 
        bowtie2 = "{sample}/logs/atac_bowtie2/bowtie2_{chunk}.log",
    shell: "bowtie2 --interleaved <(zstd -dc {input.fastq}) -x {params.index} "
           " --sam-append-comment --maxins 2000 --threads {threads} 2> {log} | "
           # -F 1804: exclude flag, exludes unmapped, next segment unmapped, secondary alignments, not passing platform q, PCR or optical duplicates
           # -f 2: flags to require, properly aligned
           # -q 30: exlude low MAPQ, set as adjustable configuration parameter
           "samtools view -F 1804 -f 2 -q 30 -1 - > {output} "
        
# Convert bam to fragments format and sort for first pass
rule atac_convert_fragments:
    input:
        bam = rules.atac_bowtie2.output
    output: temp('{sample}/atac/fragments/{chunk}.fragments.tsv')
    params:
        script = srcdir("scripts/bam_to_fragments.py"),
        memory = "4G",
    threads: 4
    shell: "python {params.script} {input} | "
           "LC_ALL=C sort -k1,1V -k2,2n -k3,3n -k4,4 -t$'\\t' "
           "-S {params.memory} --parallel={threads} > {output}"

def get_chunks(sample):
    chunk_count = (config["samples"][sample]["reads"] + chunk_size - 1) // chunk_size
    return list(range(1, chunk_count+1))

rule atac_merge_fragments:
    input: lambda w: expand(rules.atac_convert_fragments.output, sample=w.sample, chunk=get_chunks(w.sample))
    output: 
        fragments = '{sample}/atac/fragments.tsv.gz',
        index = '{sample}/atac/fragments.tsv.gz.tbi',
    params:
        memory = "4G",
        script = srcdir("scripts/dedup_fragments.py")
    shell: "LC_ALL=C sort -k1,1V -k2,2n -k3,3n -k4,4 -t$'\\t' "
        "--merge --batch-size=100 -S {params.memory} {input} | "
        "python {params.script} | "
        "bgzip -c > {output.fragments} && "
        "tabix --preset bed {output.fragments}"

# rule bowtie2: 
#     input:
#         R1 = rules.trim_adapters.output.R1,
#         R2 = rules.trim_adapters.output.R2
#     output:
#         bam = "03_raw_bams/{sequencing_run}/{sample}.bam"
#     params:
#         cluster_time = "02:00:00",
#         bowtie_genome_path = genome_lookup("bowtie_path")
#     threads: 16
#     log: 'logs/bowtie2/{sequencing_run}/{sample}.log'
#     benchmark: 'logs/bowtie2/{sequencing_run}/{sample}.runtime'
#     group: "sample_fragment_creation"
#     shell:
#         "bowtie2 -X 2000 --threads {threads} -x {params.bowtie_genome_path} -1 {input.R1} -2 {input.R2} 2> {log} "
#         "    | samtools view -b -S - -o {output.bam}"

# Alternative trim command
# "SeqPurge -a1 CTGTCTCTTATACACATCTCCGAGCCCACGAGAC -a2 CTGTCTCTTATACACATCTGACGCTGCCGACGA "
#     " -qcut 0 -ncut 0 "
#     " -threads {threads} -out1 {output.R1} -out2 {output.R2} "
#     " -in1 {input.R1} -in2 {input.R2} > {log}"

# fastp alternative
# "fastp -i {input.fastq1_bc} -I {input.fastq2_bc} -o {output.fastq1_trim} -O {output.fastq2_trim}"
#        " -h {log.html} -j {log.json} -G -Q -L -w {threads} 2> {output.stats}"
